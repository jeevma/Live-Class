{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737368b9",
   "metadata": {},
   "source": [
    "# ADK Callbacks (Doc-faithful, concise)\n",
    "\n",
    "Callbacks let you observe, modify, or override an agent’s behavior at precise points.\n",
    "\n",
    "## What you’ll learn\n",
    "- Six callbacks and when they run\n",
    "- How to let default behavior continue vs. override it\n",
    "- Minimal wiring for each type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d6c4d",
   "metadata": {},
   "source": [
    "## Where callbacks fire\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  U[User] --> R[Runner]\n",
    "  R --> A[Agent]\n",
    "  A -->|before_agent| A\n",
    "  A -->|before_model| L[LLM]\n",
    "  L -->|after_model| A\n",
    "  A -->|before_tool| T[Tool]\n",
    "  T -->|after_tool| A\n",
    "  A -->|after_agent| R --> U\n",
    "```\n",
    "\n",
    "- **before_agent / after_agent** — wrap the agent’s main work for a turn.\n",
    "- **before_model / after_model** — around the LLM request/response.\n",
    "- **before_tool / after_tool** — around each tool call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f039ec99",
   "metadata": {},
   "source": [
    "## Types and override rules\n",
    "\n",
    "| Callback | Typical purpose | Let default proceed | Override / Replace |\n",
    "|---|---|---|---|\n",
    "| `before_agent` | pre-checks, setup state | return `None` | return `types.Content` (skip agent run) |\n",
    "| `after_agent` | post-format, final edits | return `None` | return `types.Content` (replace final) |\n",
    "| `before_model` | guardrails, prompt tweaks | return `None` | return `LlmResponse` (skip LLM) |\n",
    "| `after_model` | sanitize/reshape LLM output | return `None` | return `LlmResponse` (replace LLM) |\n",
    "| `before_tool` | auth/args/rate limit | return `None` | return `dict` (skip tool, use this) |\n",
    "| `after_tool` | normalize tool result | return `None` | return `dict` (replace tool result) |\n",
    "\n",
    "Tip: Update turn/session state via the provided context objects; don’t mutate session state directly during a run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3283f8",
   "metadata": {},
   "source": [
    "## Minimal wiring (all six callbacks)\n",
    "Below: concise handlers and an `LlmAgent` that uses them. Add your tools later to see tool callbacks in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d4ab4e",
   "metadata": {
    "tags": [
     "callbacks-minimal"
    ]
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.agents.callback_context import CallbackContext\n",
    "from google.adk.models import LlmRequest, LlmResponse\n",
    "from google.genai import types\n",
    "\n",
    "# -------- Agent lifecycle --------\n",
    "def before_agent_cb(callback_context: CallbackContext) -> Optional[types.Content]:\n",
    "    # Example: mark a trace id for this turn\n",
    "    callback_context.state[\"temp:trace_id\"] = \"trace-001\"\n",
    "    return None  # allow agent to run\n",
    "\n",
    "def after_agent_cb(callback_context: CallbackContext) -> Optional[types.Content]:\n",
    "    # Example: keep default; you could return Content(...) to replace final\n",
    "    return None\n",
    "\n",
    "# -------- LLM interaction --------\n",
    "def before_model_cb(callback_context: CallbackContext, llm_request: LlmRequest) -> Optional[LlmResponse]:\n",
    "    # Example: prepend a concise system instruction\n",
    "    sys_msg = types.Content(role=\"system\", parts=[types.Part(text=\"Be concise.\")])\n",
    "    cfg = llm_request.config or types.GenerateContentConfig()\n",
    "    cfg.system_instruction = sys_msg\n",
    "    llm_request.config = cfg\n",
    "    # Example skip path: if you wanted to block, return an LlmResponse(...) here\n",
    "    return None\n",
    "\n",
    "def after_model_cb(callback_context: CallbackContext, llm_response: LlmResponse) -> Optional[LlmResponse]:\n",
    "    # Example: keep default; you could return a modified LlmResponse\n",
    "    return None\n",
    "\n",
    "# -------- Tool execution --------\n",
    "def before_tool_cb(tool, args, tool_context):\n",
    "    # Example: clamp an optional 'limit' argument if present\n",
    "    if isinstance(args, dict) and \"limit\" in args:\n",
    "        args[\"limit\"] = min(int(args[\"limit\"]), 5)\n",
    "    return None  # allow tool call\n",
    "\n",
    "def after_tool_cb(tool, args, tool_context, tool_response):\n",
    "    # Example: attach a 'source' key if tool returns a dict\n",
    "    if isinstance(tool_response, dict):\n",
    "        tool_response.setdefault(\"source\", getattr(tool, \"name\", \"tool\"))\n",
    "        return tool_response  # replaces tool result\n",
    "    return None\n",
    "\n",
    "callbacks_agent = LlmAgent(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    name=\"callbacks_agent\",\n",
    "    instruction=\"Answer helpfully in one short paragraph.\",\n",
    "    before_agent_callback=before_agent_cb,\n",
    "    after_agent_callback=after_agent_cb,\n",
    "    before_model_callback=before_model_cb,\n",
    "    after_model_callback=after_model_cb,\n",
    "    before_tool_callback=before_tool_cb,\n",
    "    after_tool_callback=after_tool_cb,\n",
    "    tools=[]\n",
    ")\n",
    "print(\"Agent ready:\", callbacks_agent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3a42a",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "   A[before_model] -->|return None| M[Call LLM]\n",
    "   A -->|return LlmResponse| X[Skip LLM<br/>use returned response]\n",
    "   M --> B[after_model]\n",
    "   B -->|return None| C[Use LLM response]\n",
    "   B -->|return LlmResponse| D[Replace response]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e759c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5feda1b4",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "   P[before_tool] -->|return None| T[Run tool]\n",
    "   P -->|return dict| S[Skip tool<br/>use returned dict]\n",
    "   T --> Q[after_tool]\n",
    "   Q -->|return None| U[Use tool result]\n",
    "   Q -->|return dict| V[Replace result]\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55599af8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
