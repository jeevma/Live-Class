{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd4dd8c",
   "metadata": {},
   "source": [
    "# ADK Tools: Built-in, Function, Third-party, MCP & OpenAPI (with diagrams & examples)\n",
    "\n",
    "This module explains **how tools work in Google ADK**, the **available tool types**, when to use which, their **limitations**, and gives runnable code templates.\n",
    "\n",
    "**What is a tool?** In ADK, a *Tool* is a capability an agent can call to act beyond text generation (web search, code execution, database queries, external APIs, even other agents). :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "**Tool families covered:**\n",
    "- Function Tools (incl. Long-running & Agent-as-Tool) :contentReference[oaicite:1]{index=1}\n",
    "- Built-in Tools: Google Search, Code Execution, Vertex AI RAG, Vertex AI Search, BigQuery :contentReference[oaicite:2]{index=2}\n",
    "- Third-party Tools (LangChain, CrewAI wrappers) :contentReference[oaicite:3]{index=3}\n",
    "- Google Cloud Tools (Apigee / App Integration / DB toolbox) :contentReference[oaicite:4]{index=4}\n",
    "- MCP Tools (consume or expose MCP) :contentReference[oaicite:5]{index=5}\n",
    "- OpenAPI Tools (auto-generate REST tools from spec) :contentReference[oaicite:6]{index=6}\n",
    "\n",
    "> **Latest constraints you must know (Sept 2025)**\n",
    "> - **Built-in tools** (like `google_search` and built-in code execution) require **Gemini 2** models and have composition limits (details below). :contentReference[oaicite:7]{index=7}\n",
    "> - ADK **parallelizes function tools** (v1.10.0+), so write async tools to benefit. :contentReference[oaicite:8]{index=8}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf8fe1",
   "metadata": {},
   "source": [
    "## Big picture: how an ADK agent decides to call tools\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User message] --> B[LlmAgent - planner]\n",
    "    B -->|No tool needed| R[Respond with text]\n",
    "    B -->|Tool call needed| C{Which tool family?}\n",
    "    C --> D[Built-in tool<br/>Google Search, Code Exec,<br/>Vertex RAG/Search, BigQuery]\n",
    "    C --> E[Function tool<br/>your Python function]\n",
    "    C --> F[Agent-as-Tool<br/>wrap specialized agent]\n",
    "    C --> G[Third-party wrapper<br/>LangChain/CrewAI]\n",
    "    C --> H[MCP toolset<br/>connect MCP server]\n",
    "    C --> I[OpenAPI toolset<br/>generate REST tools]\n",
    "    D --> J[Runner executes tool]\n",
    "    E --> J\n",
    "    F --> J\n",
    "    G --> J\n",
    "    H --> J\n",
    "    I --> J\n",
    "    J --> K[LLM summarizes results]\n",
    "    K --> L[Final user response]\n",
    "    \n",
    "    style A fill:#e1f5fe\n",
    "    style B fill:#f3e5f5\n",
    "    style C fill:#fff3e0\n",
    "    style R fill:#e8f5e8\n",
    "    style L fill:#e8f5e8\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68337d9f",
   "metadata": {},
   "source": [
    "## 1) Function Tools (your Python â†’ a tool)\n",
    "Function tools are the simplest way to add custom capabilities. ADK inspects your function signature, docstring, and types to build the calling schema the LLM uses. Supports required/optional params, `typing.Optional`, and variadics are ignored for schema. Prefer dict return values. \n",
    "\n",
    "```python\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "def convert_temperature(value: float, unit_from: str, unit_to: str = \"C\") -> dict:\n",
    "    \"\"\"Convert temperatures. Args: value; unit_from in ['C','F']; unit_to in ['C','F'] (optional, default 'C'). Returns dict.\"\"\"\n",
    "    if unit_from == unit_to:\n",
    "\n",
    "\n",
    "\n",
    "        return {\"status\": \"ok\", \"result\": value}\n",
    "    if unit_from == \"C\" and unit_to == \"F\":\n",
    "        return {\"status\": \"ok\", \"result\": (value * 9/5) + 32}\n",
    "    if unit_from == \"F\" and unit_to == \"C\":\n",
    "        return {\"status\": \"ok\", \"result\": (value - 32) * 5/9}\n",
    "    return {\"status\": \"error\", \"error_message\": \"Unsupported units\"}\n",
    "\n",
    "agent = LlmAgent(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    name=\"unit_helper\",\n",
    "    instruction=(\n",
    "        \"Use the convert_temperature tool for conversions. If tool returns status=error, explain why.\"\n",
    "    ),\n",
    "    tools=[convert_temperature],  # ADK wraps it as a FunctionTool automatically\n",
    ")\n",
    "```\n",
    "\n",
    "### Agent-as-a-Tool\n",
    "Wrap a **specialized agent** as a callable tool using `AgentTool`, letting a parent agent delegate but retain control (vs sub-agents which transfer control). Import via `google.adk.tools.agent_tool.AgentTool`. :contentReference[oaicite:11]{index=11}\n",
    "\n",
    "```python\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "\n",
    "web_researcher = LlmAgent(model=\"gemini-2.0-flash\", name=\"WebResearcher\", instruction=\"Search + summarize on a topic.\")\n",
    "math_solver = LlmAgent(model=\"gemini-2.0-flash\", name=\"MathSolver\", instruction=\"Do accurate calculations.\")\n",
    "\n",
    "root = LlmAgent(\n",
    "  model=\"gemini-2.0-flash\",\n",
    "  name=\"RootAgent\",\n",
    "  instruction=\"Use the specialized agents as tools as needed.\",\n",
    "  tools=[AgentTool(web_researcher), AgentTool(math_solver)]\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec205d",
   "metadata": {},
   "source": [
    "## 2) Built-in Tools (Google Search, Code Execution, Vertex RAG/Search, BigQuery)\n",
    "\n",
    "**Compatibility & limits:**\n",
    "- **Use Gemini 2 models** (e.g., `gemini-2.0-flash`) for built-ins like Google Search and built-in Code Execution. :contentReference[oaicite:12]{index=12}\n",
    "- **One built-in tool per (root or single) agent**; you **cannot** mix a built-in tool with other tools in the same agent, and **cannot** use built-ins inside sub-agents. Work around by wrapping specialized agents with `AgentTool`. :contentReference[oaicite:13]{index=13}\n",
    "- When using **Google Search grounding**, if suggestions are returned, you **must display them** (HTML comes in `renderedContent`).\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[Need Search + Code Exec] --> B{One agent?}\n",
    "    B -->|yes| X[Not supported with two built-ins]\n",
    "    B -->|no| C[Make SearchAgent<br/>google_search]\n",
    "    B -->|no| D[Make CodeAgent<br/>BuiltInCodeExecutor]\n",
    "    C --> E[Wrap with AgentTool]\n",
    "    D --> E\n",
    "    E --> F[RootAgent uses both tools<br/>via AgentTool]\n",
    "    \n",
    "    style A fill:#e1f5fe\n",
    "    style B fill:#fff3e0\n",
    "    style X fill:#ffebee\n",
    "    style C fill:#e8f5e8\n",
    "    style D fill:#e8f5e8\n",
    "    style E fill:#f3e5f5\n",
    "    style F fill:#e3f2fd\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f59e00",
   "metadata": {},
   "source": [
    "### Google Search (grounding)\n",
    "```python\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "search_agent = LlmAgent(\n",
    "    model=\"gemini-2.0-flash\",  # Gemini 2 required\n",
    "    name=\"Search\",\n",
    "    instruction=(\n",
    "        \"Use the google_search tool before answering. If response contains renderedContent suggestions, surface them.\"\n",
    "    ),\n",
    "    tools=[google_search],\n",
    ")\n",
    "```\n",
    "Learn more about grounding policy & behavior. :contentReference[oaicite:15]{index=15}\n",
    "\n",
    "### Built-in Code Execution\n",
    "```python\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.code_executors import BuiltInCodeExecutor\n",
    "\n",
    "code_agent = LlmAgent(\n",
    "    model=\"gemini-2.0-flash\",  # Gemini 2 required for built-in executor\n",
    "    name=\"Calculator\",\n",
    "    code_executor=BuiltInCodeExecutor(),\n",
    "    instruction=(\n",
    "        \"Write and execute short Python to compute answers. Return just the number.\"\n",
    "    ),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c0223",
   "metadata": {},
   "source": [
    "## 3) Third-party Tools (LangChain & CrewAI)\n",
    "ADK provides wrappers to reuse tools from popular ecosystems. Example below shows LangChain Tavily search via `LangchainTool`. :contentReference[oaicite:18]{index=18}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain Tavily example\n",
    "!pip -q install langchain_community tavily-python\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools.langchain_tool import LangchainTool\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "import os\n",
    "\n",
    "os.environ.setdefault(\"TAVILY_API_KEY\", \"<YOUR_KEY>\")\n",
    "tavily = TavilySearchResults(max_results=5, search_depth=\"advanced\", include_answer=True)\n",
    "adk_tavily = LangchainTool(tool=tavily)\n",
    "\n",
    "lc_agent = LlmAgent(\n",
    "  model=\"gemini-2.0-flash\",\n",
    "  name=\"LCSearch\",\n",
    "  instruction=\"Use Tavily for realtime web context before answering.\",\n",
    "  tools=[adk_tavily]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326038e",
   "metadata": {},
   "source": [
    "## 4) MCP Tools (Model Context Protocol)\n",
    "Connect ADK agents to **MCP servers** (e.g., filesystem, Google Maps) using `MCPToolset`. Use `StdioConnectionParams` (local `npx` servers) or SSE/HTTP for remote. :contentReference[oaicite:19]{index=19}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03340fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal MCP filesystem server example (local development)\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset\n",
    "from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\n",
    "from mcp import StdioServerParameters\n",
    "import os\n",
    "\n",
    "target_folder = os.path.abspath(\".\")  # pick a safe folder\n",
    "mcp_tools = MCPToolset(\n",
    "    connection_params=StdioConnectionParams(\n",
    "        server_params=StdioServerParameters(\n",
    "            command=\"npx\",\n",
    "            args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", target_folder],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "mcp_agent = LlmAgent(\n",
    "  model=\"gemini-2.0-flash\",\n",
    "  name=\"FileAssistant\",\n",
    "  instruction=\"Use MCP tools to list/read files as requested.\",\n",
    "  tools=[mcp_tools]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
